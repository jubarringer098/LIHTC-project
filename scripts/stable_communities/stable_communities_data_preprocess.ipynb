{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "usda_tract = gpd.read_file(\"../../data/raw/shapefiles/USDA_Rural_Housing_by_Tract_7054655361891465054 2/USDA_Rural_Housing_by_Tract.shp\")\n",
    "usda_tract = usda_tract.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = gpd.read_file(\"../../data/raw/shapefiles/tl_2024_13_tract/tl_2024_13_tract.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts[\"is_rural\"] = tracts[\"GEOID\"].isin(usda_tract[\"GEOID\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign pool using logic from QAP\n",
    "atlanta_fips = {\"089\", \"067\", \"121\", \"135\"}\n",
    "\n",
    "def assign_pool(row):\n",
    "    if row[\"is_rural\"]:\n",
    "        return \"rural\"\n",
    "    elif row[\"COUNTYFP\"] in atlanta_fips:\n",
    "        return \"atlanta metro\"\n",
    "    else:\n",
    "        return \"other metro\"\n",
    "\n",
    "tracts[\"pool\"] = tracts.apply(assign_pool, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel_sheets_to_dataframes(excel_file_path):\n",
    "\n",
    "    # Load the Excel file\n",
    "    excel_data = pd.ExcelFile(excel_file_path)\n",
    "    \n",
    "    dataframes = {}\n",
    "\n",
    "    # Iterate over each sheet\n",
    "    for sheet_name in excel_data.sheet_names:\n",
    "        # Read the sheet into a DataFrame\n",
    "        df = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "\n",
    "        # # Optionally drop rows and columns that are completely empty\n",
    "        df.dropna(how='all', axis=0, inplace=True)\n",
    "        df.dropna(how='all', axis=1, inplace=True)\n",
    "\n",
    "        sanitized_name = sheet_name.lower().replace(\" \", \"_\")\n",
    "        print(sanitized_name)\n",
    "\n",
    "        # Store the DataFrame in the dictionary\n",
    "        dataframes[sanitized_name] = df\n",
    "\n",
    "        # Save them as csvs\n",
    "        df.to_csv(\"../../data/preprocessed/scoring_indicators/stable_communities/\"+sanitized_name+\"_2024.csv\")\n",
    "        print(\"../../data/preprocessed/scoring_indicators/stable_communities/\"+sanitized_name+\"_2024.csv\")\n",
    "    return dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = \"../../data/raw/scoring_indicators/stable_communities/2024stablecommunities.xlsx\"\n",
    "dfs_dict = excel_sheets_to_dataframes(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2796\n",
      "2796\n",
      "2796\n",
      "2796\n",
      "2796\n"
     ]
    }
   ],
   "source": [
    "print(dfs_dict['environmental_health_index']['2020 Census Tract'].nunique())\n",
    "print(dfs_dict['transit_access_index']['2020 Census Tract'].nunique())\n",
    "print(dfs_dict['above_poverty_level']['2020 Census Tract'].nunique())\n",
    "print(dfs_dict['median_income']['2020 Census Tract'].nunique())\n",
    "print(dfs_dict['jobs_proximity_index']['2020 Census Tract'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the first two\n",
    "df_merged = pd.merge(dfs_dict['environmental_health_index'], \n",
    "                     dfs_dict['transit_access_index'],\n",
    "                     on=\"2020 Census Tract\",\n",
    "                     how=\"outer\")\n",
    "\n",
    "# Merge the next\n",
    "df_merged = pd.merge(df_merged, \n",
    "                     dfs_dict['above_poverty_level'], \n",
    "                     on=\"2020 Census Tract\", \n",
    "                     how=\"outer\")\n",
    "\n",
    "# Merge the next\n",
    "df_merged = pd.merge(df_merged, \n",
    "                     dfs_dict['median_income'], \n",
    "                     on=\"2020 Census Tract\", \n",
    "                     how=\"outer\")\n",
    "\n",
    "# Merge the final\n",
    "df_merged = pd.merge(df_merged, \n",
    "                     dfs_dict['jobs_proximity_index'], \n",
    "                     on=\"2020 Census Tract\", \n",
    "                     how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020 Census Tract                                  int64\n",
       "Environmental Health Index                       float64\n",
       "Transit Access Index                              object\n",
       "Percent of Population Above the Poverty Level     object\n",
       "Median Income                                     object\n",
       "Jobs Proximity Index                             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"2020 Census Tract\"] = df_merged[\"2020 Census Tract\"].astype(str).str.strip()\n",
    "tracts[\"GEOID\"] = tracts[\"GEOID\"].astype(str).str.strip()\n",
    "\n",
    "# Merge in pool info based on GEOID\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    tracts[[\"GEOID\", \"pool\"]],\n",
    "    left_on=\"2020 Census Tract\",\n",
    "    right_on=\"GEOID\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values from Stable Communities excel on DCA website\n",
    "pool_medians = {\n",
    "    \"atlanta metro\": {\n",
    "        \"Environmental Health Index\": 0.286,\n",
    "        \"Transit Access Index\": 0.600,\n",
    "        \"Percent of Population Above the Poverty Level\": 91.2,\n",
    "        \"Median Income\": 78538,\n",
    "        \"Jobs Proximity Index\": 0.632\n",
    "    },\n",
    "    \"other metro\": {\n",
    "        \"Environmental Health Index\": 0.430,\n",
    "        \"Transit Access Index\": 0.609,\n",
    "        \"Percent of Population Above the Poverty Level\": 86.4,\n",
    "        \"Median Income\": 60044,\n",
    "        \"Jobs Proximity Index\": 0.597\n",
    "    },\n",
    "    \"rural\": {\n",
    "        \"Environmental Health Index\": 0.672,\n",
    "        \"Transit Access Index\": 0.538,\n",
    "        \"Percent of Population Above the Poverty Level\": 85.4,\n",
    "        \"Median Income\": 55096,\n",
    "        \"Jobs Proximity Index\": 0.577\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_columns = list(pool_medians[\"rural\"].keys()) \n",
    "\n",
    "for col in indicator_columns:\n",
    "    df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')\n",
    "\n",
    "    new_col = f\"above_median_{col}\"\n",
    "    df_merged[new_col] = 0  \n",
    "\n",
    "    for pool_name in pool_medians:\n",
    "        threshold = pool_medians[pool_name][col]\n",
    "        mask = df_merged[\"pool\"].str.lower() == pool_name \n",
    "        df_merged.loc[mask, new_col] = np.where(df_merged.loc[mask, col] > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_merged.empty:\n",
    "    df_merged.to_csv('../../data/processed/scoring_indicators/stable_communities_2024_processed_v3.csv', index=False)\n",
    "else:\n",
    "    print(\"Warning: df_merged is empty. CSV file not saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
